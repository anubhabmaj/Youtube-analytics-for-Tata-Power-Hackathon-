{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9fdb003-889f-4c0f-9431-07549cd62322",
   "metadata": {},
   "source": [
    "● Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca38c70-c44c-4239-885f-70ebdcca9a89",
   "metadata": {},
   "source": [
    "1. Data Collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15808f4e-fec2-4222-a56c-caf07d5ce94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import googleapiclient.discovery\n",
    "from googleapiclient.errors import HttpError\n",
    "import io\n",
    "import json\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdf9d8d-39bb-4df5-af14-16f6de42cbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key here\n",
    "API_KEY = 'AIzaSyAc-3AyUnHZnf-edqsUTNgpjmtDOG5_r4Q'\n",
    "\n",
    "# Initialize the YouTube Data API v3 client\n",
    "youtube = googleapiclient.discovery.build('youtube', 'v3', developerKey=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc9d5f5-531c-4c79-b6cf-ceca87be00c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_videos(query, max_results=50):\n",
    "    videos = []\n",
    "\n",
    "    request = youtube.search().list(\n",
    "        q=query,\n",
    "        type='video',\n",
    "        part='id',\n",
    "        maxResults=max_results\n",
    "    )\n",
    "\n",
    "    response = request.execute()\n",
    "\n",
    "\n",
    "    for item in response['items']:\n",
    "        video_id = item['id']['videoId']\n",
    "        videos.append(video_id)\n",
    "\n",
    "    return videos\n",
    "\n",
    "def get_video_comments_with_details(video_id):\n",
    "    comments_data = []\n",
    "\n",
    "    try:\n",
    "        request = youtube.commentThreads().list(\n",
    "            part=\"snippet\",\n",
    "            videoId=video_id,\n",
    "            textFormat=\"plainText\",\n",
    "            maxResults=100\n",
    "        )\n",
    "        response = request.execute()\n",
    "\n",
    "        for comment in response['items']:\n",
    "            comment_snippet = comment['snippet']\n",
    "            top_level_comment = comment_snippet['topLevelComment']['snippet']\n",
    "            text = top_level_comment['textDisplay']\n",
    "            author = top_level_comment['authorDisplayName']\n",
    "            author_id = top_level_comment['authorChannelId']['value']\n",
    "\n",
    "            comments_data.append({\n",
    "                'VideoID': video_id,\n",
    "                'AuthorName': author,\n",
    "                'AuthorID': author_id,\n",
    "                'Comment': text\n",
    "            })\n",
    "    \n",
    "    except HttpError as e:\n",
    "        if \"commentsDisabled\" in str(e):\n",
    "            print(f\"Comments are disabled for video: {video_id}\")\n",
    "        else:\n",
    "            print(f\"Error fetching comments for video: {video_id}\")\n",
    "    \n",
    "    return comments_data\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Replace 'renewable energy sustainability' with your desired query\n",
    "    query = 'renewable energy sustainability'\n",
    "\n",
    "    # Search for videos\n",
    "    videos = search_videos(query)\n",
    "\n",
    "    # Fetch and save comments with details in a DataFrame\n",
    "    comments_details = []\n",
    "    for video_id in videos:\n",
    "        video_comments = get_video_comments_with_details(video_id)\n",
    "        comments_details.extend(video_comments)\n",
    "\n",
    "    # Convert the list of comments with details into a DataFrame\n",
    "    comments_df = pd.DataFrame(comments_details)\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    comments_df.to_csv('video_comments_with_details.csv', index=False)\n",
    "\n",
    "    print(\"Comments with details have been stored in 'video_comments_with_details22.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d99062-7a6f-4260-b7d6-83185f597d40",
   "metadata": {},
   "source": [
    "2. Data Preprocessing:\n",
    "    Clean and preprocess your data, including removing duplicates, handling missing data, and performing text normalization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f82c34-f103-4bdd-b4e9-191c73aadcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your data into a DataFrame (this example assumes you have a CSV file)\n",
    "df = pd.read_csv('video_comments_with_details.csv')  # Replace with your data file\n",
    "\n",
    "# Remove duplicate comments\n",
    "df = df.drop_duplicates(subset='Comment')\n",
    "\n",
    "# Remove blank comments (comments with only whitespace)\n",
    "df = df[df['Comment'].str.strip() != '']\n",
    "\n",
    "# Handle missing data (if applicable)\n",
    "df = df.dropna(subset=['Comment'])\n",
    "\n",
    "# Remove comments that don't contain meaningful text (e.g., comments with very few words)\n",
    "min_comment_length = 3  # Adjust this threshold as needed\n",
    "df = df[df['Comment'].str.split().str.len() >= min_comment_length]\n",
    "\n",
    "# Perform text normalization (e.g., lowercasing and punctuation removal)\n",
    "df['Comment'] = df['Comment'].str.lower()\n",
    "df['Comment'] = df['Comment'].str.replace(r'[^\\w\\s]', '')\n",
    "\n",
    "# Save the preprocessed data to a new file\n",
    "df.to_csv('preprocessed_comments_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3a0c10-3687-4108-ab59-5228eecdae11",
   "metadata": {},
   "source": [
    "3. Data Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa7bc68-1100-4d2a-8b30-bab3a8e1bd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Read the CSV file into a DataFrame\n",
    "df = pd.read_csv('comments_with_sentiment.csv')\n",
    "\n",
    "# Step 2: Define common keywords (replace with your list)\n",
    "common_keywords = [\n",
    "    \"renewable\", \"sustainable\", \"climate\", \"clean energy\", \"conservation\",\n",
    "    \"solar\", \"wind\", \"hydroelectric\", \"geothermal\", \"biomass\", \"tidal energy\",\n",
    "    \"sustainable practices\", \"environmental sustainability\", \"social sustainability\",\n",
    "    \"economic sustainability\", \"sustainable development\",\n",
    "    \"climate action\", \"carbon footprint\", \"greenhouse gases\", \"climate mitigation\",\n",
    "    \"climate adaptation\",\n",
    "    \"clean power\", \"green energy\", \"clean technology\", \"low-carbon energy\", \"energy efficiency\",\n",
    "    \"energy-saving\", \"energy conservation\", \"power reduction\",\n",
    "    \"eco-conscious\", \"environmentally friendly\", \"eco-friendly products\", \"green living\",\n",
    "    \"electric vehicles\", \"public transportation\", \"cycling\", \"sustainable mobility\",\n",
    "    \"biodiversity\", \"habitat preservation\", \"conservation efforts\",\n",
    "    \"recycling\", \"reuse\", \"reduce\", \"circular economy principles\",\n",
    "    \"sustainable architecture\", \"LEED certification\", \"green building\",\n",
    "    \"renewable sources\", \"renewable technology\", \"renewable power\", \"sustainable solutions\",\n",
    "    \"sustainable living\", \"renewable practices\", \"sustainable initiatives\",\n",
    "    \"clean environment\", \"green initiatives\", \"environmental conservation\",\n",
    "    \"renewable economy\", \"sustainability goals\", \"renewable infrastructure\", \"sustainable transportation\",\n",
    "    \"clean fuel\", \"green infrastructure\", \"sustainable consumption\", \"renewable innovations\",\n",
    "    \"sustainable policies\", \"renewable investments\", \"sustainability measures\",\n",
    "    \"clean power generation\", \"sustainable urban planning\", \"renewable solutions\", \"sustainability standards\",\n",
    "    \"renewable technologies\", \"sustainability projects\", \"clean energy sources\", \"sustainable resources\",\n",
    "    \"renewable initiatives\", \"sustainability practices\", \"clean energy solutions\", \"sustainable business\",\n",
    "    \"renewable practices\", \"renewable management\", \"sustainability assessment\", \"clean energy systems\",\n",
    "    \"sustainable development goals\", \"renewable conservation\", \"renewable strategies\", \"sustainability efforts\",\n",
    "    \"clean energy policies\", \"green energy solutions\", \"sustainable practices\",\n",
    "    \"renewable investments\", \"sustainability measures\", \"clean power generation\", \"sustainable urban planning\",\n",
    "    \"renewable solutions\", \"sustainability standards\", \"renewable technologies\", \"sustainability projects\",\n",
    "    \"clean energy sources\", \"sustainable resources\", \"renewable initiatives\", \"sustainability practices\",\n",
    "    \"clean energy solutions\", \"sustainable business\", \"renewable practices\", \"renewable management\",\n",
    "    \"sustainability assessment\", \"clean energy systems\", \"sustainable development goals\", \"renewable conservation\",\n",
    "    \"renewable strategies\", \"sustainability efforts\", \"clean energy policies\", \"green energy solutions\", \"sustainable practices\",\n",
    "    \"renewable investments\", \"sustainability measures\", \"clean power generation\", \"sustainable urban planning\",\n",
    "    \"renewable solutions\", \"sustainability standards\", \"renewable technologies\", \"sustainability projects\",\n",
    "    \"clean energy sources\", \"sustainable resources\", \"renewable initiatives\", \"sustainability practices\",\n",
    "    \"clean energy solutions\", \"sustainable business\", \"renewable practices\", \"renewable management\",\n",
    "    \"sustainability assessment\", \"clean energy systems\", \"sustainable development goals\", \"renewable conservation\",\n",
    "    \"renewable strategies\", \"sustainability efforts\", \"clean energy policies\", \"green energy solutions\", \"sustainable practices\", \"energy\", \"solar\", \"nuclear\", \"green\", \"wind\", \"waste\", \"gas\", \"electricity\",\n",
    "    \"fuel\", \"fossil\", \"oil\", \"plants\", \"coal\", \"water\", \"storage\", \"renewables\", \"technology\",\n",
    "    \"earth\", \"greenhouse\", \"batteries\", \"fuels\", \"expensive\", \"hydrogen\", \"plant\", \"global\",\n",
    "    \"turbines\", \"biomass\", \"land\", \"heat\", \"carbon\", \"co2\", \"sun\", \"environment\", \"human\",\n",
    "    \"emissions\", \"uranium\", \"government\", \"recycling\", \"battery\", \"pollution\", \"tax\", \"price\",\n",
    "    \"tons\", \"natural\", \"high\", \"production\", \"time\", \"use\"\n",
    "]\n",
    "\n",
    "\n",
    "# Step 3: Create a function to check if a comment contains common keywords\n",
    "def contains_common_keywords(comment):\n",
    "    comment = comment.lower()\n",
    "    for keyword in common_keywords:\n",
    "        if keyword in comment:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Step 4: Filter comments using the function\n",
    "filtered_comments = df[df['Comment'].apply(contains_common_keywords)]\n",
    "\n",
    "# Step 5: Save the new DataFrame to a new CSV file\n",
    "filtered_comments.to_csv('filtered_comments2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244dd3e5-5ed5-4ec1-b817-ee4eabf8b6c5",
   "metadata": {},
   "source": [
    "Identify misconceptions or gaps in knowledge related to \n",
    "renewable source by analuzing top keywords in commentss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c45418-8d0b-4a87-a15c-22c9c0e925ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "# Load the comments with sentiment data\n",
    "df = pd.read_csv('filtered_comments2.csv')\n",
    "\n",
    "# Tokenize and preprocess the comments\n",
    "df['Comment'] = df['Comment'].str.lower()\n",
    "df['Comment'] = df['Comment'].str.replace(r'[^\\w\\s]', '')\n",
    "\n",
    "# Separate comments by sentiment\n",
    "positive_comments = df[df['Sentiment Category'] == 'Positive']['Comment']\n",
    "negative_comments = df[df['Sentiment Category'] == 'Negative']['Comment']\n",
    "neutral_comments = df[df['Sentiment Category'] == 'Neutral']['Comment']\n",
    "\n",
    "# Define a list of stopwords\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "# Common keywords for identifying frequency\n",
    "common_keywords = [\n",
    "    \"renewable\", \"sustainable\", \"climate\", \"clean energy\", \"conservation\",\n",
    "    \"solar\", \"wind\", \"hydroelectric\", \"geothermal\", \"biomass\", \"tidal energy\",\n",
    "    \"sustainable practices\", \"environmental sustainability\", \"social sustainability\",\n",
    "    \"economic sustainability\", \"sustainable development\",\n",
    "    \"climate action\", \"carbon footprint\", \"greenhouse gases\", \"climate mitigation\",\n",
    "    \"climate adaptation\",\n",
    "    \"clean power\", \"green energy\", \"clean technology\", \"low-carbon energy\", \"energy efficiency\",\n",
    "    \"energy-saving\", \"energy conservation\", \"power reduction\",\n",
    "    \"eco-conscious\", \"environmentally friendly\", \"eco-friendly products\", \"green living\",\n",
    "    \"electric vehicles\", \"public transportation\", \"cycling\", \"sustainable mobility\",\n",
    "    \"biodiversity\", \"habitat preservation\", \"conservation efforts\",\n",
    "    \"recycling\", \"reuse\", \"reduce\", \"circular economy principles\",\n",
    "    \"sustainable architecture\", \"LEED certification\", \"green building\",\n",
    "    \"renewable sources\", \"renewable technology\", \"renewable power\", \"sustainable solutions\",\n",
    "    \"sustainable living\", \"renewable practices\", \"sustainable initiatives\",\n",
    "    \"clean environment\", \"green initiatives\", \"environmental conservation\",\n",
    "    \"renewable economy\", \"sustainability goals\", \"renewable infrastructure\", \"sustainable transportation\",\n",
    "    \"clean fuel\", \"green infrastructure\", \"sustainable consumption\", \"renewable innovations\",\n",
    "    \"sustainable policies\", \"renewable investments\", \"sustainability measures\",\n",
    "    \"clean power generation\", \"sustainable urban planning\", \"renewable solutions\", \"sustainability standards\",\n",
    "    \"renewable technologies\", \"sustainability projects\", \"clean energy sources\", \"sustainable resources\",\n",
    "    \"renewable initiatives\", \"sustainability practices\", \"clean energy solutions\", \"sustainable business\",\n",
    "    \"renewable practices\", \"renewable management\", \"sustainability assessment\", \"clean energy systems\",\n",
    "    \"sustainable development goals\", \"renewable conservation\", \"renewable strategies\", \"sustainability efforts\",\n",
    "    \"clean energy policies\", \"green energy solutions\", \"sustainable practices\",\n",
    "    \"renewable investments\", \"sustainability measures\", \"clean power generation\", \"sustainable urban planning\",\n",
    "    \"renewable solutions\", \"sustainability standards\", \"renewable technologies\", \"sustainability projects\",\n",
    "    \"clean energy sources\", \"sustainable resources\", \"renewable initiatives\", \"sustainability practices\",\n",
    "    \"clean energy solutions\", \"sustainable business\", \"renewable practices\", \"renewable management\",\n",
    "    \"sustainability assessment\", \"clean energy systems\", \"sustainable development goals\", \"renewable conservation\",\n",
    "    \"renewable strategies\", \"sustainability efforts\", \"clean energy policies\", \"green energy solutions\", \"sustainable practices\",\n",
    "    \"energy\", \"solar\", \"nuclear\", \"green\", \"wind\", \"waste\", \"gas\", \"electricity\",\n",
    "    \"fuel\", \"fossil\", \"oil\", \"plants\", \"coal\", \"water\", \"storage\", \"renewables\", \"technology\",\n",
    "    \"earth\", \"greenhouse\", \"batteries\", \"fuels\", \"expensive\", \"hydrogen\", \"plant\", \"global\",\n",
    "    \"turbines\", \"biomass\", \"land\", \"heat\", \"carbon\", \"co2\", \"sun\", \"environment\", \"human\",\n",
    "    \"emissions\", \"uranium\", \"government\", \"recycling\", \"battery\", \"pollution\", \"tax\", \"price\",\n",
    "    \"tons\", \"natural\", \"high\", \"production\", \"time\", \"use\"\n",
    "]\n",
    "\n",
    "# Function to extract keywords and calculate frequency for a given sentiment\n",
    "def extract_keywords(sentiment_comments, common_keywords):\n",
    "    all_sentiment_comments = ' '.join(sentiment_comments)\n",
    "    \n",
    "    # Tokenize the text\n",
    "    tokens = nltk.word_tokenize(all_sentiment_comments)\n",
    "    \n",
    "    # Remove punctuation and symbols\n",
    "    tokens = [word for word in tokens if word not in string.punctuation]\n",
    "    \n",
    "    # Remove stopwords\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Filter keywords based on common_keywords\n",
    "    tokens = [word for word in tokens if word in common_keywords]\n",
    "    \n",
    "    fdist = FreqDist(tokens)\n",
    "    common_keywords = fdist.most_common(100)  # Change the number as needed\n",
    "    \n",
    "    return common_keywords\n",
    "\n",
    "# Extract keywords for each sentiment\n",
    "positive_keywords = extract_keywords(positive_comments, common_keywords)\n",
    "negative_keywords = extract_keywords(negative_comments, common_keywords)\n",
    "neutral_keywords = extract_keywords(neutral_comments, common_keywords)\n",
    "\n",
    "# Create DataFrames from the results\n",
    "df_positive = pd.DataFrame(positive_keywords, columns=['Keyword', 'Frequency'])\n",
    "df_negative = pd.DataFrame(negative_keywords, columns=['Keyword', 'Frequency'])\n",
    "df_neutral = pd.DataFrame(neutral_keywords, columns=['Keyword', 'Frequency'])\n",
    "\n",
    "# Export DataFrames to CSV files\n",
    "df_positive.to_csv('positive_keywords.csv', index=False)\n",
    "df_negative.to_csv('negative_keywords.csv', index=False)\n",
    "df_neutral.to_csv('neutral_keywords.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19a845e",
   "metadata": {},
   "source": [
    "Top watched vedios on youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacbffb4-400b-4217-9612-56accf08aa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting   API key\n",
    "import googleapiclient.discovery\n",
    "import datetime\n",
    "\n",
    "# Setting our API key\n",
    "API_KEY = 'AIzaSyBAWKHwXeOxokQfCx6RvNxJkX8BFc2scTY'\n",
    "\n",
    "# Create a YouTube Data API service\n",
    "youtube = googleapiclient.discovery.build(\"youtube\", \"v3\", developerKey='AIzaSyBAWKHwXeOxokQfCx6RvNxJkX8BFc2scTY')\n",
    "\n",
    "# Function to search for renewable and clean energy videos\n",
    "def search_renewable_energy_videos(api_key):\n",
    "    youtube = googleapiclient.discovery.build(\"youtube\", \"v3\", developerKey=api_key)\n",
    "\n",
    "    search_response = youtube.search().list(\n",
    "        q=\"renewable energy\",\n",
    "        type=\"video\",\n",
    "        order=\"viewCount\",\n",
    "        part=\"id\",\n",
    "        maxResults=50  # You can adjust the number of results\n",
    "    ).execute()\n",
    "\n",
    "    return search_response\n",
    "\n",
    "# Function to get the video statistics (including view counts) by video ID\n",
    "def get_video_statistics(api_key, video_ids):\n",
    "    youtube = googleapiclient.discovery.build(\"youtube\", \"v3\", developerKey=api_key)\n",
    "\n",
    "    video_response = youtube.videos().list(\n",
    "        id=\",\".join(video_ids),\n",
    "        part=\"snippet,statistics\"\n",
    "    ).execute()\n",
    "\n",
    "    return video_response\n",
    "\n",
    "# Function to extract the time of day from video publishedAt timestamps\n",
    "def get_time_of_day_from_published_at(video_response):\n",
    "    times_of_day = []\n",
    "    for item in video_response.get(\"items\", []):\n",
    "        published_at = item[\"snippet\"][\"publishedAt\"]\n",
    "        timestamp = datetime.datetime.fromisoformat(published_at.replace(\"Z\", \"+00:00\"))\n",
    "        times_of_day.append(timestamp.strftime(\"%H:%M\"))\n",
    "    return times_of_day\n",
    "\n",
    "# Main code\n",
    "search_results = search_renewable_energy_videos(API_KEY)\n",
    "video_ids = [result[\"id\"][\"videoId\"] for result in search_results.get(\"items\", [])]\n",
    "\n",
    "video_response = get_video_statistics(API_KEY, video_ids)\n",
    "times_of_day = get_time_of_day_from_published_at(video_response)\n",
    "\n",
    "# Count and find the most common time of day\n",
    "from collections import Counter\n",
    "time_counts = Counter(times_of_day)\n",
    "most_common_time = time_counts.most_common(1)[0]\n",
    "\n",
    "print(f\"Most Common Time of Day to Watch Renewable Energy Videos: {most_common_time[0]}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2546d50c",
   "metadata": {},
   "source": [
    "Importing view count,duration,likes,etc of a vedio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dade0843",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "api_key = 'AIzaSyAdw62weNnmR82iadUwd6yIgevOjpBJ5dI'\n",
    "#channel_id = 'UCnz-ZXXER4jOvuED5trXfEA'\n",
    "channel_ids = ['UCnz-ZXXER4jOvuED5trXfEA', # techTFQ\n",
    "               'UCLLw7jmFsvfIVaUFsLs8mlQ', # Luke Barousse\n",
    "               'UCiT9RITQ9PW6BhXK0y2jaeg', # Ken Jee\n",
    "               'UC7cs8q-gJRlGwj4A8OmCmXg', # Alex the analyst\n",
    "               'UC2UXDak6o7rBm23k3Vv5dww' ,# Tina Huang\n",
    "                'UCCz5pvnMksWgbWh5MKMH-vQ'  #tatapower\n",
    "              ]\n",
    "\n",
    "youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "\n",
    "\n",
    "def get_channel_stats(youtube, channel_ids):\n",
    "    all_data = []\n",
    "    request = youtube.channels().list(\n",
    "        part='snippet,contentDetails,statistics',\n",
    "        id=','.join(channel_ids))\n",
    "    response = request.execute()\n",
    "\n",
    "    for i in range(len(response['items'])):\n",
    "        data = dict(Channel_name=response['items'][i]['snippet']['title'],\n",
    "                    Subscribers=response['items'][i]['statistics']['subscriberCount'],\n",
    "                    Views=response['items'][i]['statistics']['viewCount'],\n",
    "                    Total_videos=response['items'][i]['statistics']['videoCount'],\n",
    "                    playlist_id=response['items'][i]['contentDetails']['relatedPlaylists']['uploads'])\n",
    "        all_data.append(data)\n",
    "\n",
    "    return all_data\n",
    "\n",
    "channel_statistics = get_channel_stats(youtube, channel_ids)\n",
    "\n",
    "print(channel_statistics)\n",
    "\n",
    "channel_data = pd.DataFrame(channel_statistics)\n",
    "channel_data['Subscribers'] = pd.to_numeric(channel_data['Subscribers'])\n",
    "channel_data['Views'] = pd.to_numeric(channel_data['Views'])\n",
    "channel_data['Total_videos'] = pd.to_numeric(channel_data['Total_videos'])\n",
    "channel_data.dtypes\n",
    "print(channel_data)\n",
    "\n",
    "\n",
    "import os\n",
    "import googleapiclient.discovery\n",
    "\n",
    "# Set your API key and the YouTube video ID\n",
    "# Set your API key and the YouTube video ID\n",
    "API_KEY = 'AIzaSyAdw62weNnmR82iadUwd6yIgevOjpBJ5dI'\n",
    "VIDEO_ID = \"RD4tOTaqSTI\"\n",
    "# Creating a YouTube Data API service\n",
    "youtube = googleapiclient.discovery.build(\"youtube\", \"v3\", developerKey='AIzaSyAdw62weNnmR82iadUwd6yIgevOjpBJ5dI')\n",
    "\n",
    "# Getting video details including content details\n",
    "video_response = youtube.videos().list(\n",
    "    part=\"snippet,contentDetails,statistics\",\n",
    "    id=VIDEO_ID\n",
    ").execute()\n",
    "\n",
    "# Extracting the view count, video duration\n",
    "view_count = int(video_response[\"items\"][0][\"statistics\"][\"viewCount\"])\n",
    "video_duration_iso = video_response[\"items\"][0][\"contentDetails\"][\"duration\"]\n",
    "print(\"view count is\",view_count,\"and vedio duration is=\",video_duration_iso)\n",
    "\n",
    "# Converting video duration from ISO 8601 format to seconds\n",
    "video_duration = 0\n",
    "if \"M\" in video_duration_iso and \"S\" in video_duration_iso:\n",
    "    minutes = int(video_duration_iso.split(\"M\")[0][2:])\n",
    "    seconds = int(video_duration_iso.split(\"M\")[1][0:-1])\n",
    "    video_duration = minutes * 60 + seconds\n",
    "elif \"M\" in video_duration_iso:\n",
    "    minutes = int(video_duration_iso.split(\"M\")[0][2:])\n",
    "    video_duration = minutes * 60\n",
    "elif \"S\" in video_duration_iso:\n",
    "    seconds = int(video_duration_iso.split(\"S\")[0])\n",
    "    video_duration = seconds\n",
    "\n",
    "# Calculating the first 10% of the video duration\n",
    "first_10_percent = video_duration / 10\n",
    "\n",
    "# Calculating the estimated number of viewers for the first 10%\n",
    "estimated_viewers_first_10_percent = int((view_count * first_10_percent) / video_duration)\n",
    "\n",
    "# Printing the results\n",
    "print(f\"Total Views: {view_count}\")\n",
    "print(f\"Video Duration: {video_duration} seconds\")\n",
    "print(f\"Estimated Viewers for First 10%: {estimated_viewers_first_10_percent}\")\n",
    "\n",
    "#the above code we just assumed that the viewer is watching in a linear fashion\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c92b36",
   "metadata": {},
   "source": [
    "If we are a channel and if we have the view durations,we can plot a normal distribution for te same to assess how much duration the users are watching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6901c608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated viewer watch times\n",
    "viewer_watch_times = [602, 720, 830, 410, 302, 752, 930, 810, 730, 60, 712, 230, 1500, 800]\n",
    "\n",
    "# Calculate the time threshold for the first 30% of the video\n",
    "total_watch_time = sum(viewer_watch_times)\n",
    "threshold_time = 0.3 * total_watch_time\n",
    "\n",
    "# Calculate the number of viewers who watched the first 30%\n",
    "num_viewers_watched_30_percent = sum(time <= threshold_time for time in viewer_watch_times)\n",
    "\n",
    "# Print the result\n",
    "print(f\"Number of Viewers who Watched the First 30%: {num_viewers_watched_30_percent}\")\n",
    "\n",
    "import numpy as np\n",
    "from statistics import mean, median, mode\n",
    "\n",
    "\n",
    "# Calculate mean, median, and mode\n",
    "mean_watch_time = mean(viewer_watch_times)\n",
    "median_watch_time = median(viewer_watch_times)\n",
    "try:\n",
    "    mode_watch_time = mode(viewer_watch_times)\n",
    "except StatisticsError:\n",
    "    mode_watch_time = \"No unique mode found\"\n",
    "\n",
    "# Print the results\n",
    "print(f\"Mean Watch Time: {mean_watch_time:.2f} seconds\")\n",
    "print(f\"Median Watch Time: {median_watch_time:.2f} seconds\")\n",
    "print(f\"Mode Watch Time: {mode_watch_time}\")\n",
    "\n",
    "std_deviation = np.std(viewer_watch_times)\n",
    "\n",
    "print(f\"Standard Deviation: {std_deviation:.2f}\")\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# Generate simulated viewer watch times\n",
    "watch_times = np.random.normal(mean_watch_time, std_deviation, view_count)\n",
    "\n",
    "# Create a histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(watch_times, bins=20, edgecolor='black', alpha=0.7)\n",
    "plt.title(\"Viewer Watch Time Histogram\")\n",
    "plt.xlabel(\"Watch Time (seconds)\")\n",
    "plt.ylabel(\"Number of Viewers\")\n",
    "plt.grid(True)\n",
    "\n",
    "# Calculate statistics\n",
    "mean_watch = np.mean(watch_times)\n",
    "median_watch = np.median(watch_times)\n",
    "std_dev = np.std(watch_times)\n",
    "\n",
    "# Display statistics\n",
    "print(f\"Mean Watch Time: {mean_watch:.2f} seconds\")\n",
    "print(f\"Median Watch Time: {median_watch:.2f} seconds\")\n",
    "print(f\"Standard Deviation: {std_dev:.2f} seconds\")\n",
    "\n",
    "# Show the histogram\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0191cb0",
   "metadata": {},
   "source": [
    "Top 50 vedios for the search \"Renewable and sustainable energy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c51eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding most watched content on youtube w.r.t. renewable energy\n",
    "\n",
    "import googleapiclient.discovery\n",
    "\n",
    "# Set your API key\n",
    "API_KEY = 'AIzaSyBAWKHwXeOxokQfCx6RvNxJkX8BFc2scTY'\n",
    "\n",
    "# Create a YouTube Data API service\n",
    "youtube = googleapiclient.discovery.build(\"youtube\", \"v3\", developerKey='AIzaSyBAWKHwXeOxokQfCx6RvNxJkX8BFc2scTY')\n",
    "\n",
    "# Search for renewable energy content\n",
    "def search_renewable_energy_videos(api_key):\n",
    "    youtube = googleapiclient.discovery.build(\"youtube\", \"v3\", developerKey=api_key)\n",
    "\n",
    "    search_response = youtube.search().list(\n",
    "        q=\"renewable energy\",\n",
    "        type=\"video\",\n",
    "        order=\"viewCount\",\n",
    "        part=\"id\",\n",
    "        maxResults=10\n",
    "    ).execute()\n",
    "\n",
    "    return search_response\n",
    "\n",
    "# Print the top results\n",
    "search_results = search_renewable_energy_videos(API_KEY)\n",
    "for search_result in search_results.get(\"items\", []):\n",
    "    video_id = search_result[\"id\"][\"videoId\"]\n",
    "    print(f\"Video ID: {video_id}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f656062b",
   "metadata": {},
   "source": [
    "Time of the day when people watch \"Sustainable energy content the most\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bc204f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting   API key\n",
    "import googleapiclient.discovery\n",
    "import datetime\n",
    "\n",
    "# Setting our API key\n",
    "API_KEY = 'AIzaSyBAWKHwXeOxokQfCx6RvNxJkX8BFc2scTY'\n",
    "\n",
    "# Create a YouTube Data API service\n",
    "youtube = googleapiclient.discovery.build(\"youtube\", \"v3\", developerKey='AIzaSyBAWKHwXeOxokQfCx6RvNxJkX8BFc2scTY')\n",
    "\n",
    "# Function to search for renewable and clean energy videos\n",
    "def search_renewable_energy_videos(api_key):\n",
    "    youtube = googleapiclient.discovery.build(\"youtube\", \"v3\", developerKey=api_key)\n",
    "\n",
    "    search_response = youtube.search().list(\n",
    "        q=\"renewable energy\",\n",
    "        type=\"video\",\n",
    "        order=\"viewCount\",\n",
    "        part=\"id\",\n",
    "        maxResults=50  # You can adjust the number of results\n",
    "    ).execute()\n",
    "\n",
    "    return search_response\n",
    "\n",
    "# Function to get the video statistics (including view counts) by video ID\n",
    "def get_video_statistics(api_key, video_ids):\n",
    "    youtube = googleapiclient.discovery.build(\"youtube\", \"v3\", developerKey=api_key)\n",
    "\n",
    "    video_response = youtube.videos().list(\n",
    "        id=\",\".join(video_ids),\n",
    "        part=\"snippet,statistics\"\n",
    "    ).execute()\n",
    "\n",
    "    return video_response\n",
    "\n",
    "# Function to extract the time of day from video publishedAt timestamps\n",
    "def get_time_of_day_from_published_at(video_response):\n",
    "    times_of_day = []\n",
    "    for item in video_response.get(\"items\", []):\n",
    "        published_at = item[\"snippet\"][\"publishedAt\"]\n",
    "        timestamp = datetime.datetime.fromisoformat(published_at.replace(\"Z\", \"+00:00\"))\n",
    "        times_of_day.append(timestamp.strftime(\"%H:%M\"))\n",
    "    return times_of_day\n",
    "\n",
    "# Main code\n",
    "search_results = search_renewable_energy_videos(API_KEY)\n",
    "video_ids = [result[\"id\"][\"videoId\"] for result in search_results.get(\"items\", [])]\n",
    "\n",
    "video_response = get_video_statistics(API_KEY, video_ids)\n",
    "times_of_day = get_time_of_day_from_published_at(video_response)\n",
    "\n",
    "# Count and find the most common time of day\n",
    "from collections import Counter\n",
    "time_counts = Counter(times_of_day)\n",
    "most_common_time = time_counts.most_common(1)[0]\n",
    "\n",
    "print(f\"Most Common Time of Day to Watch Renewable Energy Videos: {most_common_time[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c679387",
   "metadata": {},
   "source": [
    "Collecting data of all the top 50 vedios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabd52a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "# Set your YouTube Data API key\n",
    "api_key = 'AIzaSyBAWKHwXeOxokQfCx6RvNxJkX8BFc2scTY'\n",
    "\n",
    "# Set the topic you want to search for\n",
    "topic = 'renewable energy and sustainability'\n",
    "\n",
    "# Set the maximum number of results\n",
    "max_results = 50\n",
    "\n",
    "# Define a function to collect video data\n",
    "def collect_top_videos(api_key, topic, max_results):\n",
    "    youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "\n",
    "    # Search for videos related to the topic and order by view count\n",
    "    search_response = youtube.search().list(\n",
    "        q=topic,\n",
    "        type='video',\n",
    "        part='id',\n",
    "        maxResults=max_results,\n",
    "        order='viewCount'\n",
    "    ).execute()\n",
    "\n",
    "    video_data = []\n",
    "    for item in search_response['items']:\n",
    "        video_id = item['id']['videoId']\n",
    "        video_details = youtube.videos().list(part='snippet,statistics', id=video_id).execute()\n",
    "        snippet = video_details['items'][0]['snippet']\n",
    "        statistics = video_details['items'][0]['statistics']\n",
    "        video_data.append({\n",
    "            'Video ID': video_id,\n",
    "            'Title': snippet['title'],\n",
    "            'Description': snippet['description'],\n",
    "            'Views': statistics['viewCount'],\n",
    "            'Likes': statistics.get('likeCount', 0),\n",
    "        })\n",
    "\n",
    "    return video_data\n",
    "\n",
    "# Analyze video data\n",
    "def analyze_video_data(video_data):\n",
    "    df = pd.DataFrame(video_data)\n",
    "    return df\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Collect data for the top 50 videos\n",
    "    video_data = collect_top_videos(api_key, topic, max_results)\n",
    "\n",
    "    # Analyze video data\n",
    "    df = analyze_video_data(video_data)\n",
    "\n",
    "    # Display the DataFrame\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.expand_frame_repr', False)\n",
    "    print(df)\n",
    "\n",
    "# Group all descriptions into one list\n",
    "    all_descriptions = df['Description'].tolist()\n",
    "\n",
    "    # Display the list of descriptions\n",
    "    for description in all_descriptions:\n",
    "        print(description)\n",
    "\n",
    "####\n",
    "import os\n",
    "import pandas as pd\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "# Set your YouTube Data API key\n",
    "api_key = 'AIzaSyBAWKHwXeOxokQfCx6RvNxJkX8BFc2scTY'\n",
    "\n",
    "# Set the topic you want to search for\n",
    "topic = 'renewable energy and sustainability'\n",
    "\n",
    "# Set the maximum number of results\n",
    "max_results = 50\n",
    "\n",
    "# Define a function to collect video data\n",
    "def collect_top_videos(api_key, topic, max_results):\n",
    "    youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "\n",
    "    # Search for videos related to the topic and order by view count\n",
    "    search_response = youtube.search().list(\n",
    "        q=topic,\n",
    "        type='video',\n",
    "        part='id',\n",
    "        maxResults=max_results,\n",
    "        order='viewCount'\n",
    "    ).execute()\n",
    "\n",
    "    video_data = []\n",
    "    for item in search_response['items']:\n",
    "        video_id = item['id']['videoId']\n",
    "        video_details = youtube.videos().list(part='snippet', id=video_id).execute()\n",
    "        snippet = video_details['items'][0]['snippet']\n",
    "        video_data.append({\n",
    "            'Video ID': video_id,\n",
    "            'Title': snippet['title'],\n",
    "            'Description': snippet['description'],\n",
    "        })\n",
    "\n",
    "    return video_data\n",
    "\n",
    "# Analyze video data\n",
    "def analyze_video_data(video_data):\n",
    "    df = pd.DataFrame(video_data)\n",
    "    return df\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Collect data for the top 50 videos\n",
    "    video_data = collect_top_videos(api_key, topic, max_results)\n",
    "\n",
    "    # Analyze video data\n",
    "    df = analyze_video_data(video_data)\n",
    "\n",
    "    # Save description-related data to a CSV file\n",
    "    df[['Video ID', 'Description']].to_csv('video_description_data.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d87ce5",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
