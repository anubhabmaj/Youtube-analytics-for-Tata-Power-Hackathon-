{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c9ab9c4",
   "metadata": {},
   "source": [
    "## Renewable & Sustainable Future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1395ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Video ID                                              Title    Views  \\\n",
      "0  1x_zsJ4zlVY  Go Solar with India's #1 Solar Rooftop company...   865889   \n",
      "1  H3w4PKf-ep8  Go Solar with India's #1 Solar Rooftop company...    40294   \n",
      "2  OBEZCwhTpng  Go Solar with India's #1 Solar Rooftop company...   503642   \n",
      "3  bHBX2dqdCJo  Go Solar with India's #1 Solar Rooftop company...   882416   \n",
      "4  -0vRPmsldOM  Go Solar with India's #1 Solar Rooftop company...   327840   \n",
      "5  yZwdjjcDNYs  An Ode to Energy Independence by Birds of Plan...  6853300   \n",
      "6  ZXxkLwDCGEg  Go Solar with India's #1 Solar Rooftop company...   858988   \n",
      "7  _UshsnZANe8  Go Solar with India's #1 Solar Rooftop company...  1561073   \n",
      "8  -cFrbK8v3tA                   Tata Power's Do Green Initiative     2811   \n",
      "9  EakOLJa8zg4  Go Solar with India's #1 Solar Rooftop company...   322171   \n",
      "\n",
      "  Likes Comments  \n",
      "0     0        0  \n",
      "1     0        0  \n",
      "2     0        0  \n",
      "3    17        0  \n",
      "4     0        0  \n",
      "5    23        0  \n",
      "6    39        0  \n",
      "7     2        0  \n",
      "8   157        2  \n",
      "9     1        0  \n"
     ]
    }
   ],
   "source": [
    "import googleapiclient.discovery\n",
    "import pandas as pd\n",
    "\n",
    "# Set your YouTube Data API key\n",
    "API_KEY = 'AIzaSyAKluPmAHaM0k-jSFTexrmG7GDo-Klh470'\n",
    "\n",
    "# Initialize the YouTube Data API v3 client\n",
    "youtube = googleapiclient.discovery.build('youtube', 'v3', developerKey=API_KEY)\n",
    "\n",
    "# Function to fetch video statistics for a given channel ID\n",
    "def fetch_channel_video_statistics(channel_id):\n",
    "    video_data = []\n",
    "    \n",
    "    # Fetch video statistics for the channel\n",
    "    request = youtube.search().list(\n",
    "        type='video',\n",
    "        part='id',\n",
    "        channelId=channel_id,\n",
    "        maxResults=10,  # You can increase this if you want more videos\n",
    "    )\n",
    "    \n",
    "    response = request.execute()\n",
    "    video_ids = [item['id']['videoId'] for item in response['items']]\n",
    "    \n",
    "    for video_id in video_ids:\n",
    "        request = youtube.videos().list(\n",
    "            part='snippet,statistics',\n",
    "            id=video_id\n",
    "        )\n",
    "        \n",
    "        response = request.execute()\n",
    "        video_info = response['items'][0]\n",
    "        \n",
    "        title = video_info['snippet']['title']\n",
    "        views = video_info['statistics'].get('viewCount', 0)\n",
    "        likes = video_info['statistics'].get('likeCount', 0)\n",
    "        comments = video_info['statistics'].get('commentCount', 0)\n",
    "        video_id = video_info['id']\n",
    "\n",
    "        video_data.append([video_id, title, views, likes, comments])\n",
    "\n",
    "    return video_data\n",
    "\n",
    "# Define the channel ID for Tatamotor\n",
    "channel_id = 'UCCz5pvnMksWgbWh5MKMH-vQ'\n",
    "\n",
    "# Fetch video statistics\n",
    "video_stats = fetch_channel_video_statistics(channel_id)\n",
    "\n",
    "# Create a DataFrame\n",
    "column_names = ['Video ID', 'Title', 'Views', 'Likes', 'Comments']\n",
    "df = pd.DataFrame(video_stats, columns=column_names)\n",
    "\n",
    "# Drop the 'Shares' column if it exists\n",
    "df.drop(columns=['Shares'], axis=1, errors='ignore', inplace=True)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(r'C:\\Users\\anjal\\OneDrive\\Documents\\MINDSPARK\\tata power\\tatamotor_video_statistics.csv', index=False)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d95a6c",
   "metadata": {},
   "source": [
    "## Time Duration Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d7d7f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import googleapiclient.discovery\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Define your API key\n",
    "API_KEY = 'AIzaSyAulBsE6h5Zu4XPUDaEm6tw2SL2YFi1OEk'\n",
    "\n",
    "# Initialize the YouTube Data API v3 client\n",
    "youtube = googleapiclient.discovery.build('youtube', 'v3', developerKey=API_KEY)\n",
    "\n",
    "# Function to retrieve all videos from a channel\n",
    "def get_all_videos(channel_id):\n",
    "    videos = []\n",
    "\n",
    "    next_page_token = None\n",
    "    while True:\n",
    "        request = youtube.search().list(\n",
    "            part='id',\n",
    "            channelId=channel_id,\n",
    "            maxResults=50,\n",
    "            pageToken=next_page_token,\n",
    "            order='date'  # You can change the order if needed\n",
    "        )\n",
    "\n",
    "        response = request.execute()\n",
    "\n",
    "        for item in response['items']:\n",
    "            if item['id']['kind'] == 'youtube#video':\n",
    "                videos.append(item['id']['videoId'])\n",
    "\n",
    "        next_page_token = response.get('nextPageToken')\n",
    "\n",
    "        if not next_page_token:\n",
    "            break\n",
    "\n",
    "    return videos\n",
    "\n",
    "# Function to convert ISO 8601 duration to minutes\n",
    "def iso8601_to_minutes(duration):\n",
    "    duration_match = re.match(r'PT(\\d+H)?(\\d+M)?(\\d+S)?', duration)\n",
    "    hours = int(duration_match.group(1)[:-1]) if duration_match.group(1) else 0\n",
    "    minutes = int(duration_match.group(2)[:-1]) if duration_match.group(2) else 0\n",
    "    seconds = int(duration_match.group(3)[:-1]) if duration_match.group(3) else 0\n",
    "    total_minutes = hours * 60 + minutes + seconds / 60\n",
    "    return total_minutes\n",
    "\n",
    "# Function to get video details, including duration in minutes\n",
    "def get_video_details(video_id):\n",
    "    request = youtube.videos().list(\n",
    "        part='snippet, contentDetails',\n",
    "        id=video_id\n",
    "    )\n",
    "    response = request.execute()\n",
    "    video_info = response['items'][0]\n",
    "\n",
    "    video_details = {\n",
    "        'VideoID': video_info['id'],\n",
    "        'Title': video_info['snippet']['title'],\n",
    "        'Duration': iso8601_to_minutes(video_info['contentDetails']['duration'])\n",
    "    }\n",
    "\n",
    "    return video_details\n",
    "\n",
    "# Channel ID for the channel you want to retrieve videos from\n",
    "channel_id = 'UCCz5pvnMksWgbWh5MKMH-vQ'\n",
    "\n",
    "# Get all video IDs from the channel\n",
    "video_ids = get_all_videos(channel_id)\n",
    "\n",
    "# Retrieve video details, including duration in minutes, for each video\n",
    "video_details_list = [get_video_details(video_id) for video_id in video_ids]\n",
    "\n",
    "# Convert the list of video details into a DataFrame\n",
    "video_df = pd.DataFrame(video_details_list)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "video_df.to_csv(r'C:\\Users\\anjal\\OneDrive\\Documents\\MINDSPARK\\tata power\\channel_videos_with_duration_minutes.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fb53ed",
   "metadata": {},
   "source": [
    "## video uploaded every year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6ab6cc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import googleapiclient.discovery\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Define your API key\n",
    "API_KEY = 'AIzaSyAulBsE6h5Zu4XPUDaEm6tw2SL2YFi1OEk'\n",
    "\n",
    "# Initialize the YouTube Data API v3 client\n",
    "youtube = googleapiclient.discovery.build('youtube', 'v3', developerKey=API_KEY)\n",
    "\n",
    "# Function to retrieve all videos from a channel\n",
    "def get_all_videos(channel_id):\n",
    "    videos = []\n",
    "\n",
    "    next_page_token = None\n",
    "    while True:\n",
    "        request = youtube.search().list(\n",
    "            part='id,snippet',\n",
    "            channelId=channel_id,\n",
    "            maxResults=50,\n",
    "            pageToken=next_page_token,\n",
    "            order='date'  # You can change the order if needed\n",
    "        )\n",
    "\n",
    "        response = request.execute()\n",
    "\n",
    "        for item in response['items']:\n",
    "            if item['id']['kind'] == 'youtube#video':\n",
    "                videos.append(item)\n",
    "\n",
    "        next_page_token = response.get('nextPageToken')\n",
    "\n",
    "        if not next_page_token:\n",
    "            break\n",
    "\n",
    "    return videos\n",
    "\n",
    "# Function to convert ISO 8601 duration to minutes\n",
    "def iso8601_to_minutes(duration):\n",
    "    duration_match = re.match(r'PT(\\d+H)?(\\d+M)?(\\d+S)?', duration)\n",
    "    hours = int(duration_match.group(1)[:-1]) if duration_match.group(1) else 0\n",
    "    minutes = int(duration_match.group(2)[:-1]) if duration_match.group(2) else 0\n",
    "    seconds = int(duration_match.group(3)[:-1]) if duration_match.group(3) else 0\n",
    "    total_minutes = hours * 60 + minutes + seconds / 60\n",
    "    return total_minutes\n",
    "\n",
    "# Function to get video details, including duration in minutes\n",
    "def get_video_details(video):\n",
    "    video_info = video['snippet']\n",
    "    upload_date = video_info['publishedAt']\n",
    "    year = upload_date[:4]\n",
    "\n",
    "    duration = video.get('contentDetails', {}).get('duration', 'PT0S')  # Default to 'PT0S' if 'duration' is not available\n",
    "\n",
    "    video_details = {\n",
    "        'VideoID': video['id']['videoId'],\n",
    "        'Title': video_info['title'],\n",
    "        'Year': year,\n",
    "        'Duration': iso8601_to_minutes(duration)\n",
    "    }\n",
    "\n",
    "    return video_details\n",
    "\n",
    "# Channel ID for the channel you want to retrieve videos from\n",
    "channel_id = 'UCCz5pvnMksWgbWh5MKMH-vQ'\n",
    "\n",
    "# Get all videos from the channel\n",
    "videos = get_all_videos(channel_id)\n",
    "\n",
    "# Retrieve video details, including duration in minutes, for each video\n",
    "video_details_list = [get_video_details(video) for video in videos]\n",
    "\n",
    "# Convert the list of video details into a DataFrame\n",
    "video_df = pd.DataFrame(video_details_list)\n",
    "\n",
    "# Group videos by year and count the number of videos in each year\n",
    "video_counts = video_df['Year'].value_counts().reset_index()\n",
    "video_counts.columns = ['Year', 'VideoCount']\n",
    "\n",
    "# Save the DataFrame to a CSV file with only year and video count\n",
    "video_counts.to_csv(r'C:\\Users\\anjal\\OneDrive\\Documents\\MINDSPARK\\tata power\\video_uploaded_every_year.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d6f5db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3480936b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239810b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
